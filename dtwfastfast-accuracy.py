import os
import json
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    accuracy_score,
    f1_score,
)
from fastdtw import fastdtw
from scipy.spatial.distance import euclidean

# å¯¼å…¥ joblib ç”¨äºå¹¶è¡ŒåŒ–
from joblib import Parallel, delayed
import warnings

warnings.filterwarnings("ignore")

# ===============================
# å‚æ•°è®¾ç½®
# ===============================
# !!! ä¿®æ”¹ï¼šä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œå‡è®¾è„šæœ¬ä¸demobbå’Œlabels.csvåœ¨åŒä¸€ç›®å½•
DATA_FOLDER = "demobb"
LABEL_FILE = "labels.csv"

# DTW + KNN å‚æ•°
K_NEIGHBORS = 5  # KNNçš„Kå€¼
DTW_WINDOW = 50  # DTWçª—å£å¤§å°
USE_ADAPTIVE_WINDOW = True  # æ˜¯å¦ä½¿ç”¨è‡ªé€‚åº”çª—å£
MAX_DTW_DISTANCE = 1e9  # DTWæœ€å¤§è·ç¦»é˜ˆå€¼ï¼Œè¶…è¿‡è§†ä¸ºæ— ç©·å¤§

# å¹¶è¡ŒåŒ–å‚æ•°
N_JOBS = -1  # å¹¶è¡Œæ ¸å¿ƒæ•°ã€‚-1 è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨æ ¸å¿ƒã€‚

# äº¤å‰éªŒè¯å‚æ•°
N_FOLDS = 5  # KæŠ˜äº¤å‰éªŒè¯çš„æŠ˜æ•°
PERFORM_CV = False  # æ˜¯å¦æ‰§è¡Œäº¤å‰éªŒè¯ï¼ˆDTWè®¡ç®—æ…¢ï¼Œé»˜è®¤å…³é—­ï¼‰

RANDOM_STATE = 42
SCALE_FEATURES = True
NAN_STRATEGY = "interpolate"
MIN_VALID_FRAMES = 10
MAX_VALID_FRAMES = 500  # æœ€å¤§å¸§æ•°é™åˆ¶ï¼Œé˜²æ­¢åºåˆ—è¿‡é•¿
OUTLIER_CLIP_PERCENTILE = 99  # å¼‚å¸¸å€¼è£å‰ªç™¾åˆ†ä½

# ç‰¹å¾é…ç½®
USE_ANGLE = True  # æ˜¯å¦ä½¿ç”¨è§’åº¦
USE_VELOCITY = False  # æ˜¯å¦ä½¿ç”¨è§’é€Ÿåº¦
USE_ACCELERATION = True  # æ˜¯å¦ä½¿ç”¨è§’åŠ é€Ÿåº¦

# ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®
CONFIDENCE_THRESHOLD_LOW = 0.3
CONFIDENCE_THRESHOLD_HIGH = 0.7

PREDICTION_STRATEGY = "standard"

np.random.seed(RANDOM_STATE)


# ===============================
# ç‰¹å¾æå–å‡½æ•°
# ===============================
def compute_derivatives(angles):
    """
    è®¡ç®—è§’åº¦çš„ä¸€é˜¶å¯¼æ•°(è§’é€Ÿåº¦)å’ŒäºŒé˜¶å¯¼æ•°(è§’åŠ é€Ÿåº¦)
    """
    velocity = np.gradient(angles, axis=0)
    acceleration = np.gradient(velocity, axis=0)
    return velocity, acceleration


def extract_features(seq):
    """
    æ ¹æ®é…ç½®æå–ç‰¹å¾ï¼šè§’åº¦ã€è§’é€Ÿåº¦ã€è§’åŠ é€Ÿåº¦
    """
    if seq.size == 0:
        base_shape = (0, 5)
        empty_seq = np.empty(base_shape)
        seq_deriv1 = np.empty(base_shape)
        seq_deriv2 = np.empty(base_shape)
    else:
        empty_seq = seq
        seq_deriv1, seq_deriv2 = compute_derivatives(seq)

    features_list = []

    if USE_ANGLE:
        features_list.append(empty_seq)
    if USE_VELOCITY:
        features_list.append(seq_deriv1)
    if USE_ACCELERATION:
        features_list.append(seq_deriv2)

    if len(features_list) == 0:
        raise ValueError("è‡³å°‘éœ€è¦é€‰æ‹©ä¸€ç§ç‰¹å¾ç±»å‹ï¼")

    features = np.hstack(features_list)
    return features


# ===============================
# æ•°æ®åŠ è½½å‡½æ•°
# ===============================
def load_json_angles(json_path):
    with open(json_path, "r") as f:
        data = json.load(f)
    frames = data.get("frames", [])

    seq = []
    for f in frames:
        if "joints" not in f or not all(
            k in f["joints"]
            for k in [
                "shoulder_angle",
                "elbow_angle",
                "hip_angle",
                "knee_angle",
                "ankle_angle",
            ]
        ):
            continue

        angles = [
            f["joints"]["shoulder_angle"],
            f["joints"]["elbow_angle"],
            f["joints"]["hip_angle"],
            f["joints"]["knee_angle"],
            f["joints"]["ankle_angle"],
        ]
        seq.append(angles)

    seq = np.array(seq, dtype=float)

    if seq.size == 0:
        return extract_features(seq)

    has_nan = np.isnan(seq).any()
    if has_nan:
        if NAN_STRATEGY == "interpolate":
            seq = interpolate_nan(seq)
        elif NAN_STRATEGY == "drop":
            seq = drop_nan_frames(seq)

    features = extract_features(seq)
    return features


def interpolate_nan(seq):
    df = pd.DataFrame(seq)
    df = df.interpolate(method="linear", limit_direction="both", axis=0)
    df = df.fillna(df.mean())
    df = df.fillna(0)
    return df.values


def drop_nan_frames(seq):
    mask = ~np.isnan(seq).any(axis=1)
    return seq[mask]


def is_valid_sequence(seq):
    """éªŒè¯åºåˆ—æ˜¯å¦æœ‰æ•ˆ"""
    if seq.size == 0:
        return False
    if len(seq) < MIN_VALID_FRAMES:
        return False
    if np.isnan(seq).all():
        return False
    if np.isinf(seq).any():
        return False
    return True


def clip_outliers(seq, percentile=99):
    """
    è£å‰ªå¼‚å¸¸å€¼åˆ°æŒ‡å®šç™¾åˆ†ä½
    """
    if seq.size == 0:
        return seq

    seq_clipped = seq.copy()

    for i in range(seq.shape[1]):
        col = seq[:, i]
        lower = np.percentile(col, 100 - percentile)
        upper = np.percentile(col, percentile)
        seq_clipped[:, i] = np.clip(col, lower, upper)

    return seq_clipped


def resample_sequence(seq, max_length=None):
    """
    å¦‚æœåºåˆ—è¿‡é•¿ï¼Œè¿›è¡Œé‡é‡‡æ ·
    """
    if seq.size == 0:
        return seq

    if max_length is None or len(seq) <= max_length:
        return seq

    original_indices = np.linspace(0, len(seq) - 1, len(seq))
    target_indices = np.linspace(0, len(seq) - 1, max_length)

    resampled = np.zeros((max_length, seq.shape[1]))
    for i in range(seq.shape[1]):
        resampled[:, i] = np.interp(target_indices, original_indices, seq[:, i])

    return resampled


# ===============================
# DTWè·ç¦»è®¡ç®—å‡½æ•° (æ ¸å¿ƒé€»è¾‘)
# ===============================
def compute_dtw_distance(seq1, seq2):
    """
    è®¡ç®—ä¸¤ä¸ªå¤šç»´æ—¶é—´åºåˆ—ä¹‹é—´çš„DTWè·ç¦»ï¼ˆä½¿ç”¨FastDTWï¼‰
    """
    # æ£€æŸ¥è¾“å…¥æœ‰æ•ˆæ€§
    if seq1.size == 0 or seq2.size == 0:
        return MAX_DTW_DISTANCE

    if np.isnan(seq1).any() or np.isnan(seq2).any():
        return MAX_DTW_DISTANCE
    if np.isinf(seq1).any() or np.isinf(seq2).any():
        return MAX_DTW_DISTANCE

    try:
        # ç¡®å®šçª—å£å¤§å°
        if USE_ADAPTIVE_WINDOW:
            len_diff = abs(len(seq1) - len(seq2))
            radius = min(DTW_WINDOW, max(10, len_diff + 10))
        else:
            radius = DTW_WINDOW

        # FastDTWä½¿ç”¨æ¬§æ°è·ç¦»æ¯”è¾ƒå¸§ä¸å¸§
        distance, _ = fastdtw(seq1, seq2, dist=euclidean, radius=radius)

        if np.isnan(distance) or np.isinf(distance):
            return MAX_DTW_DISTANCE

        return distance

    except Exception:
        # ä»»ä½•è®¡ç®—å¤±è´¥éƒ½è¿”å›æœ€å¤§è·ç¦»
        return MAX_DTW_DISTANCE


# ===============================
# DTW-KNNåˆ†ç±»å™¨ (å¹¶è¡ŒåŒ–ä¿®æ”¹)
# ===============================
class DTW_KNN_Classifier:
    """
    åŸºäºDTWè·ç¦»çš„KNNåˆ†ç±»å™¨ (ä½¿ç”¨Joblibå¹¶è¡ŒåŒ–)
    """

    def __init__(self, n_neighbors=5, n_jobs=N_JOBS):
        self.n_neighbors = n_neighbors
        self.n_jobs = n_jobs  # å¹¶è¡Œæ ¸å¿ƒæ•°
        self.X_train = None
        self.y_train = None

    def fit(self, X_train, y_train):
        """
        è®­ç»ƒæ¨¡å‹ï¼ˆå­˜å‚¨è®­ç»ƒæ•°æ®ï¼‰
        """
        self.X_train = X_train
        self.y_train = np.array(y_train)
        return self

    def predict_single(self, seq):
        """
        å¯¹å•ä¸ªåºåˆ—è¿›è¡Œé¢„æµ‹ï¼ˆå¹¶è¡Œè®¡ç®—è·ç¦»ï¼‰
        """
        # --- å…³é”®å¹¶è¡ŒåŒ–éƒ¨åˆ† ---
        # ä½¿ç”¨ joblib.Parallel å¹¶è¡Œè®¡ç®—å½“å‰æµ‹è¯•æ ·æœ¬ä¸æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„ DTW è·ç¦»
        distances = Parallel(n_jobs=self.n_jobs, prefer="threads")(
            delayed(compute_dtw_distance)(seq, train_seq) for train_seq in self.X_train
        )
        # --- å¹¶è¡ŒåŒ–ç»“æŸ ---

        distances = np.array(distances)

        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è·ç¦»éƒ½æ˜¯æ— æ•ˆçš„
        valid_distances = distances[distances < MAX_DTW_DISTANCE]
        if len(valid_distances) == 0:
            print("    è­¦å‘Š: æ‰€æœ‰DTWè·ç¦»æ— æ•ˆï¼Œå›é€€åˆ°éšæœºé¢„æµ‹")
            # å›é€€ï¼šé€‰æ‹©æœ€è¿‘çš„ï¼ˆå°½ç®¡æ˜¯MAX_DTWï¼‰é‚»å±…
            k_nearest_indices = np.argsort(distances)[: self.n_neighbors]
            k_nearest_distances = distances[k_nearest_indices]
            k_nearest_labels = self.y_train[k_nearest_indices]
        else:
            # æ‰¾åˆ°Kä¸ªæœ€è¿‘é‚»
            k_nearest_indices = np.argsort(distances)[: self.n_neighbors]
            k_nearest_distances = distances[k_nearest_indices]
            k_nearest_labels = self.y_train[k_nearest_indices]

        # æŠ•ç¥¨å†³å®šé¢„æµ‹æ ‡ç­¾
        unique_labels, counts = np.unique(k_nearest_labels, return_counts=True)
        predicted_label = unique_labels[np.argmax(counts)]

        return predicted_label, k_nearest_distances, k_nearest_labels

    def predict(self, X_test):
        """
        å¯¹å¤šä¸ªåºåˆ—è¿›è¡Œé¢„æµ‹
        """
        predictions = []
        for seq in X_test:
            pred_label, _, _ = self.predict_single(seq)
            predictions.append(pred_label)
        return predictions


# ===============================
# ç½®ä¿¡åº¦è®¡ç®—å‡½æ•°ï¼ˆåŸºäºDTWè·ç¦»ï¼‰
# ===============================
def calculate_confidence_metrics_dtw(distances, neighbors_labels, all_labels):
    """
    åŸºäºDTWè·ç¦»å’Œæœ€è¿‘é‚»æ ‡ç­¾è®¡ç®—ç½®ä¿¡åº¦ï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰
    """
    valid_mask = (
        (distances < MAX_DTW_DISTANCE) & (~np.isnan(distances)) & (~np.isinf(distances))
    )

    if not valid_mask.any():
        predicted_label = neighbors_labels[0]
        return {
            "predicted_label": predicted_label,
            "max_probability": 0.0,
            "margin": 0.0,
            "entropy": 1.0,
            "normalized_entropy": 1.0,
            "confidence_score": 0.0,
            "all_probabilities": {label: 1.0 / len(all_labels) for label in all_labels},
            "weighted_probabilities": {
                label: 1.0 / len(all_labels) for label in all_labels
            },
            "avg_distance": MAX_DTW_DISTANCE,
            "min_distance": MAX_DTW_DISTANCE,
        }

    valid_distances = distances[valid_mask]
    valid_labels = neighbors_labels[valid_mask]

    # 1. åŸºäºæŠ•ç¥¨çš„æ¦‚ç‡ä¼°è®¡
    unique_labels, counts = np.unique(valid_labels, return_counts=True)
    vote_probs = counts / len(valid_labels)

    label_probs = {label: 0.0 for label in all_labels}
    for label, prob in zip(unique_labels, vote_probs):
        label_probs[label] = prob

    predicted_label = unique_labels[np.argmax(counts)]
    max_probability = np.max(vote_probs)

    # 2. åŸºäºè·ç¦»çš„æƒé‡æ¦‚ç‡
    weights = 1.0 / (valid_distances + 1e-6)
    weights_sum = np.sum(weights)
    if weights_sum < 1e-6:
        weights = np.ones_like(weights) / len(weights)
    else:
        weights = weights / weights_sum

    weighted_probs = {}
    for label in all_labels:
        mask = valid_labels == label
        weighted_probs[label] = np.sum(weights[mask]) if mask.any() else 0.0

    # 3. Margin
    sorted_probs = sorted(vote_probs, reverse=True)
    margin = sorted_probs[0] - (sorted_probs[1] if len(sorted_probs) > 1 else 0)

    # 4. Entropy
    probs = np.array(list(label_probs.values()))
    probs_safe = probs + 1e-10
    entropy = -np.sum(probs * np.log(probs_safe))
    max_entropy = np.log(len(all_labels))
    normalized_entropy = entropy / max_entropy if max_entropy > 0 else 0

    # 5. ç»¼åˆç½®ä¿¡åº¦åˆ†æ•°
    min_distance = np.min(valid_distances)
    distance_confidence = 1.0 / (1.0 + min_distance / 100)
    confidence_score = max_probability * distance_confidence * (1 - normalized_entropy)

    return {
        "predicted_label": predicted_label,
        "max_probability": max_probability,
        "margin": margin,
        "entropy": entropy,
        "normalized_entropy": normalized_entropy,
        "confidence_score": confidence_score,
        "all_probabilities": label_probs,
        "weighted_probabilities": weighted_probs,
        "avg_distance": np.mean(valid_distances),
        "min_distance": min_distance,
    }


def predict_with_strategy(seq, classifier, all_labels, strategy="standard"):
    """
    æ ¹æ®ä¸åŒç­–ç•¥è¿›è¡Œé¢„æµ‹
    """
    pred_label, distances, neighbors_labels = classifier.predict_single(seq)
    confidence_metrics = calculate_confidence_metrics_dtw(
        distances, neighbors_labels, all_labels
    )

    if strategy == "standard":
        final_pred = confidence_metrics["predicted_label"]
    elif strategy == "confidence_weighted":
        if confidence_metrics["confidence_score"] < CONFIDENCE_THRESHOLD_LOW:
            final_pred = "UNCERTAIN"
        else:
            final_pred = confidence_metrics["predicted_label"]
    elif strategy == "margin_based":
        if confidence_metrics["margin"] < 0.3:
            final_pred = "UNCERTAIN"
        else:
            final_pred = confidence_metrics["predicted_label"]
    else:
        final_pred = confidence_metrics["predicted_label"]

    return final_pred, confidence_metrics


# ===============================
# åŠ è½½æ•°æ®
# ===============================
print("=" * 70)
print("æ¨¡å‹é…ç½®: DTW + KNN (å¹¶è¡ŒåŒ–)")
print(f"  - Kå€¼: {K_NEIGHBORS}")
print(f"  - DTWçª—å£: {DTW_WINDOW}")
print(f"  - å¹¶è¡Œæ ¸å¿ƒæ•°: {N_JOBS if N_JOBS != -1 else 'ALL'}")
print("=" * 70)
print("ç‰¹å¾é…ç½®:")
print(f"  - ä½¿ç”¨è§’åº¦: {USE_ANGLE}")
print(f"  - ä½¿ç”¨è§’é€Ÿåº¦: {USE_VELOCITY}")
print(f"  - ä½¿ç”¨è§’åŠ é€Ÿåº¦: {USE_ACCELERATION}")

# è®¡ç®—ç‰¹å¾ç»´åº¦
feature_dim = 0
if USE_ANGLE:
    feature_dim += 5
if USE_VELOCITY:
    feature_dim += 5
if USE_ACCELERATION:
    feature_dim += 5
print(f"  - æ€»ç‰¹å¾ç»´åº¦: {feature_dim}")
print("=" * 70)
print("æ•°æ®å¤„ç†é…ç½®:")
print(f"  - æœ€å°å¸§æ•°: {MIN_VALID_FRAMES}")
print(f"  - æœ€å¤§å¸§æ•°: {MAX_VALID_FRAMES} (é‡é‡‡æ ·)")
print(f"  - å¼‚å¸¸å€¼è£å‰ªç™¾åˆ†ä½: {OUTLIER_CLIP_PERCENTILE}")
print("=" * 70)

if not os.path.exists(LABEL_FILE):
    print(f"è‡´å‘½é”™è¯¯: æ ‡ç­¾æ–‡ä»¶æœªæ‰¾åˆ°: {LABEL_FILE}")
    exit()

if not os.path.exists(DATA_FOLDER):
    print(f"è‡´å‘½é”™è¯¯: æ•°æ®æ–‡ä»¶å¤¹æœªæ‰¾åˆ°: {DATA_FOLDER}")
    exit()

labels_df = pd.read_csv(LABEL_FILE)
print(f"\nLoaded labels.csv: {len(labels_df)} entries")

sequences, labels, video_ids = [], [], []
skipped_count = 0

for _, row in labels_df.iterrows():
    json_path = os.path.join(DATA_FOLDER, row["video_id"])
    if os.path.exists(json_path):
        try:
            seq = load_json_angles(json_path)

            seq = clip_outliers(seq, OUTLIER_CLIP_PERCENTILE)

            if len(seq) > MAX_VALID_FRAMES:
                seq = resample_sequence(seq, MAX_VALID_FRAMES)

            if is_valid_sequence(seq):
                sequences.append(seq)
                labels.append(row["label"])
                video_ids.append(row["video_id"])
            else:
                skipped_count += 1
        except Exception as e:
            print(f"[é”™è¯¯] å¤„ç†æ–‡ä»¶å¤±è´¥: {row['video_id']}, é”™è¯¯: {e}")
            skipped_count += 1
    else:
        skipped_count += 1

print(f"\nå·²æˆåŠŸåŠ è½½ {len(sequences)} ä¸ªæ ·æœ¬")
print(f"è·³è¿‡/å¤±è´¥: {skipped_count} ä¸ªæ ·æœ¬")

if not sequences:
    print("è‡´å‘½é”™è¯¯: æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•åºåˆ—ã€‚")
    exit()

seq_lengths = [len(s) for s in sequences]
print(f"\nåºåˆ—é•¿åº¦ç»Ÿè®¡:")
print(f"  - æœ€å°é•¿åº¦: {min(seq_lengths)} å¸§")
print(f"  - æœ€å¤§é•¿åº¦: {max(seq_lengths)} å¸§")
print(f"  - å¹³å‡é•¿åº¦: {np.mean(seq_lengths):.1f} å¸§")

label_counts = pd.Series(labels).value_counts()
print(f"\nå„ç±»åˆ«æ ·æœ¬æ•°:\n{label_counts}")

print("\n" + "=" * 70)
print("=== äº¤å‰éªŒè¯è¯„ä¼° ===")
print("=" * 70)

if PERFORM_CV and len(sequences) >= N_FOLDS:
    print(f"\næ­£åœ¨è¿›è¡Œ {N_FOLDS} æŠ˜äº¤å‰éªŒè¯...")
    print("âš ï¸  è­¦å‘Š: DTWè®¡ç®—è¾ƒæ…¢ï¼Œä½†å·²ä½¿ç”¨å¹¶è¡ŒåŠ é€Ÿ")

    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)

    cv_accuracies = []
    cv_f1_scores = []
    fold_idx = 1

    labels_np = np.array(labels)

    for train_idx, val_idx in skf.split(sequences, labels_np):
        print(f"\n  æŠ˜ {fold_idx}/{N_FOLDS}:")

        X_cv_train = [sequences[i] for i in train_idx]
        y_cv_train = labels_np[train_idx]
        X_cv_val = [sequences[i] for i in val_idx]
        y_cv_val = labels_np[val_idx]

        if SCALE_FEATURES:
            scaler_cv = StandardScaler()
            all_frames_cv = np.vstack(X_cv_train)
            scaler_cv.fit(all_frames_cv)
            X_cv_train = [scaler_cv.transform(x) for x in X_cv_train]
            X_cv_val = [scaler_cv.transform(x) for x in X_cv_val]

        clf_cv = DTW_KNN_Classifier(n_neighbors=K_NEIGHBORS, n_jobs=N_JOBS)  # ä½¿ç”¨å¹¶è¡Œ
        clf_cv.fit(X_cv_train, y_cv_train)
        y_cv_pred = clf_cv.predict(X_cv_val)

        fold_acc = accuracy_score(y_cv_val, y_cv_pred)
        fold_f1 = f1_score(y_cv_val, y_cv_pred, average="macro", zero_division=0)

        cv_accuracies.append(fold_acc)
        cv_f1_scores.append(fold_f1)

        print(f"    å‡†ç¡®ç‡: {fold_acc:.3f}")
        print(f"    å®å¹³å‡F1: {fold_f1:.3f}")

        fold_idx += 1

    mean_acc = np.mean(cv_accuracies)
    std_acc = np.std(cv_accuracies)
    mean_f1 = np.mean(cv_f1_scores)
    std_f1 = np.std(cv_f1_scores)

    print("\n" + "-" * 70)
    print("äº¤å‰éªŒè¯ç»“æœæ±‡æ€»:")
    print("-" * 70)
    print(f"å¹³å‡å‡†ç¡®ç‡: {mean_acc:.3f} Â± {std_acc:.3f}")
    print(f"\nå¹³å‡å®F1åˆ†æ•°: {mean_f1:.3f} Â± {std_f1:.3f}")
    print("-" * 70)

    cv_results = pd.DataFrame(
        {
            "fold": range(1, N_FOLDS + 1),
            "accuracy": cv_accuracies,
            "macro_f1": cv_f1_scores,
        }
    )
    cv_results.to_csv("cross_validation_results.csv", index=False)
    print(f"\nğŸ’¾ äº¤å‰éªŒè¯ç»“æœå·²ä¿å­˜è‡³: cross_validation_results.csv")

else:
    if not PERFORM_CV:
        print("\nâš ï¸  äº¤å‰éªŒè¯å·²ç¦ç”¨ (PERFORM_CV=False)")
    else:
        print(f"\nâš ï¸  æ ·æœ¬æ•°({len(sequences)})å°‘äºæŠ˜æ•°({N_FOLDS})ï¼Œè·³è¿‡äº¤å‰éªŒè¯")

# ===============================
# åˆ’åˆ†æ•°æ®é›†
# ===============================
X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(
    sequences,
    labels,
    video_ids,
    test_size=0.2,
    random_state=RANDOM_STATE,
    stratify=labels,
)
print(f"\nè®­ç»ƒé›†: {len(X_train)} ({len(X_train)/(len(X_train)+len(X_test))*100:.1f}%)")
print(f"æµ‹è¯•é›†: {len(X_test)} ({len(X_test)/(len(X_train)+len(X_test))*100:.1f}%)")

# ===============================
# ç‰¹å¾ç¼©æ”¾ï¼ˆå¸¦å¼‚å¸¸å€¼å¤„ç†ï¼‰
# ===============================
if SCALE_FEATURES:
    scaler = StandardScaler()
    all_train_frames = np.vstack(X_train)

    if np.isinf(all_train_frames).any():
        print("è­¦å‘Š: è®­ç»ƒæ•°æ®ä¸­åŒ…å«æ— ç©·å¤§å€¼ï¼Œè¿›è¡Œè£å‰ª...")
        all_train_frames[np.isinf(all_train_frames)] = np.nan
        df_temp = pd.DataFrame(all_train_frames)
        df_temp = df_temp.fillna(df_temp.mean())
        all_train_frames = df_temp.values

    scaler.fit(all_train_frames)

    X_train_scaled = []
    for x in X_train:
        x_scaled = scaler.transform(x)
        x_scaled[np.isinf(x_scaled)] = 0
        x_scaled[np.isnan(x_scaled)] = 0
        X_train_scaled.append(x_scaled)
    X_train = X_train_scaled

    X_test_scaled = []
    for x in X_test:
        x_scaled = scaler.transform(x)
        x_scaled[np.isinf(x_scaled)] = 0
        x_scaled[np.isnan(x_scaled)] = 0
        X_test_scaled.append(x_scaled)
    X_test = X_test_scaled

    print("ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆï¼ˆå·²å¤„ç†å¼‚å¸¸å€¼ï¼‰")

# ===============================
# è®­ç»ƒDTW-KNNæ¨¡å‹
# ===============================
print("\næ­£åœ¨è®­ç»ƒ DTW-KNN æ¨¡å‹...")
classifier = DTW_KNN_Classifier(n_neighbors=K_NEIGHBORS, n_jobs=N_JOBS)  # ä½¿ç”¨å¹¶è¡Œ
classifier.fit(X_train, y_train)
print(f"âœ… DTW-KNN æ¨¡å‹è®­ç»ƒå®Œæˆï¼ˆå­˜å‚¨äº† {len(X_train)} ä¸ªè®­ç»ƒæ ·æœ¬ï¼‰")

# ===============================
# é¢„æµ‹ä¸ç½®ä¿¡åº¦åˆ†æ
# ===============================
print(f"\nä½¿ç”¨é¢„æµ‹ç­–ç•¥: {PREDICTION_STRATEGY}")
print("å¼€å§‹é¢„æµ‹ï¼ˆè®¡ç®—DTWè·ç¦»å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰...")
print(
    f"æç¤º: å…±éœ€è®¡ç®— {len(X_test)} Ã— {len(X_train)} = {len(X_test) * len(X_train)} å¯¹DTWè·ç¦» (å·²ä½¿ç”¨ {N_JOBS if N_JOBS != -1 else 'ALL'} ä¸ªæ ¸å¿ƒåŠ é€Ÿ)"
)

y_pred = []
confidence_results = []
unique_labels = sorted(set(y_train))
failed_predictions = 0

for i, seq in enumerate(X_test):
    # ä»…åœ¨éå¹¶è¡Œæ¨¡å¼ä¸‹æ‰æ˜¾ç¤ºè¯¦ç»†è¿›åº¦ï¼Œå¦åˆ™å¹¶è¡Œè¾“å‡ºä¼šæ··ä¹±
    if N_JOBS == 1 and ((i + 1) % 5 == 0 or i == 0 or i == len(X_test) - 1):
        print(f"  è¿›åº¦: {i+1}/{len(X_test)} ({(i+1)/len(X_test)*100:.1f}%)")

    try:
        # predict_single å†…éƒ¨ç°åœ¨æ˜¯å¹¶è¡Œè®¡ç®—
        pred_label, conf_metrics = predict_with_strategy(
            seq, classifier, unique_labels, PREDICTION_STRATEGY
        )
        y_pred.append(pred_label)

        confidence_results.append(
            {
                "video_id": ids_test[i],
                "true_label": y_test[i],
                "predicted_label": pred_label,
                "confidence_score": conf_metrics["confidence_score"],
                "max_probability": conf_metrics["max_probability"],
                "margin": conf_metrics["margin"],
                "entropy": conf_metrics["normalized_entropy"],
                "avg_distance": conf_metrics["avg_distance"],
                "min_distance": conf_metrics["min_distance"],
                "is_correct": pred_label == y_test[i],
                "all_probs": conf_metrics["all_probabilities"],
            }
        )
    except Exception as e:
        print(f"  é”™è¯¯: é¢„æµ‹æ ·æœ¬ {ids_test[i]} å¤±è´¥: {e}")
        default_label = unique_labels[0]
        y_pred.append(default_label)
        confidence_results.append(
            {
                "video_id": ids_test[i],
                "true_label": y_test[i],
                "predicted_label": default_label,
                "confidence_score": 0.0,
                "max_probability": 0.0,
                "margin": 0.0,
                "entropy": 1.0,
                "avg_distance": MAX_DTW_DISTANCE,
                "min_distance": MAX_DTW_DISTANCE,
                "is_correct": default_label == y_test[i],
                "all_probs": {},
            }
        )
        failed_predictions += 1

print("âœ… é¢„æµ‹å®Œæˆï¼")
if failed_predictions > 0:
    print(f"âš ï¸  è­¦å‘Š: {failed_predictions} ä¸ªæ ·æœ¬é¢„æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")

confidence_df = pd.DataFrame(confidence_results)

# ===============================
# åŸºæœ¬è¯„ä¼°ç»“æœ
# ===============================
labels_sorted = sorted(unique_labels)

if "UNCERTAIN" in y_pred:
    y_pred_filtered = [
        p if p != "UNCERTAIN" else y_test[i] for i, p in enumerate(y_pred)
    ]
    print(f"\nå‘ç° {y_pred.count('UNCERTAIN')} ä¸ªä½ç½®ä¿¡åº¦é¢„æµ‹")
else:
    y_pred_filtered = y_pred

all_present_labels = sorted(list(set(y_test) | set(y_pred_filtered)))
if "UNCERTAIN" in all_present_labels:
    all_present_labels.remove("UNCERTAIN")


cm = confusion_matrix(y_test, y_pred_filtered, labels=all_present_labels)
acc = accuracy_score(y_test, y_pred_filtered)

print("\n" + "=" * 70)
print("=== åŸºæœ¬åˆ†ç±»ç»“æœ ===")
print("=" * 70)
print(f"å‡†ç¡®ç‡: {acc:.3f}")
print(f"\næ··æ·†çŸ©é˜µ (è¡Œ=çœŸå®, åˆ—=é¢„æµ‹):\n{cm}")
print("æ ‡ç­¾:", all_present_labels)

report_str = classification_report(
    y_test, y_pred_filtered, target_names=all_present_labels, zero_division=0
)
report_dict = classification_report(
    y_test,
    y_pred_filtered,
    target_names=all_present_labels,
    output_dict=True,
    zero_division=0,
)
print(f"\nè¯¦ç»†æŠ¥å‘Š:\n{report_str}")

print("\n" + "=" * 70)
print("=== å„ç±»åˆ«F1åˆ†æ•° ===")
print("=" * 70)
print(f"{'ç±»åˆ«':<15} {'F1-Score':<12} {'Precision':<12} {'Recall':<12} {'Support'}")
print("-" * 70)
for label in all_present_labels:
    if label in report_dict:
        f1 = report_dict[label]["f1-score"]
        precision = report_dict[label]["precision"]
        recall = report_dict[label]["recall"]
        support = report_dict[label]["support"]
        print(f"{label:<15} {f1:<12.3f} {precision:<12.3f} {recall:<12.3f} {support}")

macro_f1 = report_dict["macro avg"]["f1-score"]
weighted_f1 = report_dict["weighted avg"]["f1-score"]
print("-" * 70)
print(f"{'å®å¹³å‡ (Macro)':<15} {macro_f1:<12.3f}")
print(f"{'åŠ æƒå¹³å‡ (Weighted)':<15} {weighted_f1:<12.3f}")

# ===============================
# ç½®ä¿¡åº¦ç»Ÿè®¡åˆ†æ
# ===============================
print("\n" + "=" * 70)
print("=== ç½®ä¿¡åº¦åˆ†æ ===")
print("=" * 70)

if confidence_df.empty:
    print("ç½®ä¿¡åº¦DataFrameä¸ºç©ºï¼Œè·³è¿‡åˆ†æã€‚")
else:
    print(f"\næ•´ä½“ç½®ä¿¡åº¦ç»Ÿè®¡:")
    print(f"  å¹³å‡ç½®ä¿¡åº¦: {confidence_df['confidence_score'].mean():.3f}")
    print(f"  ç½®ä¿¡åº¦ä¸­ä½æ•°: {confidence_df['confidence_score'].median():.3f}")

    correct_conf = confidence_df[confidence_df["is_correct"]]["confidence_score"].mean()
    incorrect_conf = confidence_df[~confidence_df["is_correct"]][
        "confidence_score"
    ].mean()
    print(f"\næ­£ç¡®vsé”™è¯¯é¢„æµ‹çš„ç½®ä¿¡åº¦å¯¹æ¯”:")
    print(f"  æ­£ç¡®é¢„æµ‹å¹³å‡ç½®ä¿¡åº¦: {correct_conf:.3f}")
    print(f"  é”™è¯¯é¢„æµ‹å¹³å‡ç½®ä¿¡åº¦: {incorrect_conf:.3f}")

    correct_dist = confidence_df[confidence_df["is_correct"]]["avg_distance"].mean()
    incorrect_dist = confidence_df[~confidence_df["is_correct"]]["avg_distance"].mean()
    print(f"\næ­£ç¡®vsé”™è¯¯é¢„æµ‹çš„DTWè·ç¦»å¯¹æ¯”:")
    print(f"  æ­£ç¡®é¢„æµ‹å¹³å‡è·ç¦»: {correct_dist:.2f}")
    print(f"  é”™è¯¯é¢„æµ‹å¹³å‡è·ç¦»: {incorrect_dist:.2f}")

output_file = "confidence_analysis_dtw_knn_parallel.csv"
confidence_df.to_csv(output_file, index=False)
print(f"\nğŸ’¾ å®Œæ•´åˆ†æç»“æœå·²ä¿å­˜è‡³: {output_file}")

print("\n" + "=" * 70)
print("=== æ€§èƒ½æ€»ç»“ ===")
print("=" * 70)
print(
    f"""
åŠ é€Ÿæ–¹æ³•: CPUå¤šæ ¸å¹¶è¡ŒåŒ– (Joblib)
æ ¸å¿ƒæ•°: {N_JOBS if N_JOBS != -1 else 'ALL'}
é¢„è®¡åŠ é€Ÿæ¯”: æ¥è¿‘æ ¸å¿ƒæ•° (ä¾‹å¦‚ï¼Œ8æ ¸CPUä¸Šå¯èƒ½æé«˜çº¦7-8å€é€Ÿåº¦)ã€‚

æ€§èƒ½æŒ‡æ ‡:
  - æµ‹è¯•é›†å‡†ç¡®ç‡: {acc:.3f}
  - æµ‹è¯•é›†å®å¹³å‡F1: {macro_f1:.3f}"""
)

if PERFORM_CV and "mean_acc" in locals():
    print(f"  - äº¤å‰éªŒè¯å‡†ç¡®ç‡: {mean_acc:.3f} Â± {std_acc:.3f}")

print("=" * 70)
